{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "## svm\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_CLASSIFIER = ['MLP'] # \"ELM\"\n",
    "\n",
    "def classify(X_train, y_train, X_test, y_test, classifier, search_type='grid'):\n",
    "    \"\"\"\n",
    "    Classify the data using a Random Forest Classifier\n",
    "    :param X_train: Training data\n",
    "    :param y_train: Training labels\n",
    "    :param X_test: Testing data\n",
    "    :param y_test: Testing labels\n",
    "    :param search_type: Type of search to perform\n",
    "    :return: Accuracy of the classifier\n",
    "    \"\"\"\n",
    "    # Create a Random Forest Classifier\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "   \n",
    "    # clf = MLPClassifier(activation='logistic', hidden_layer_sizes=(100,), max_iter=500, solver='sgd') ### getting error using this\n",
    "\n",
    "    # Define the parameters to search\n",
    "    # param_dict = {\n",
    "    #     'hidden_layer_sizes': [(50,50,50),(100,100, 50), (150,100,50),],\n",
    "    #     'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    #     'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    #     'max_iter': [500, 1000],\n",
    "        \n",
    "    # }\n",
    "    \n",
    "    param_dict = {\n",
    "    'n_estimators': [200],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [5],\n",
    "    # 'min_samples_leaf': [1],\n",
    "    'min_weight_fraction_leaf': [0.4],\n",
    "    'max_features': ['sqrt'],\n",
    "    # 'max_leaf_nodes': [None],\n",
    "    'min_impurity_decrease': [0.4],\n",
    "    'bootstrap': [True],\n",
    "    'oob_score': [False],\n",
    "    # 'n_jobs': [-1],\n",
    "    'random_state': [42],\n",
    "    # 'verbose': [1],\n",
    "    # 'warm_start': [True],\n",
    "    # 'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}],\n",
    "    'ccp_alpha': [0.45],\n",
    "    # 'max_samples': [0.99],\n",
    "    # 'monotonic_cst': [0],\n",
    "} ### Zahid\n",
    "    \n",
    "    \n",
    "\n",
    "    # Perform the search\n",
    "    if search_type == 'grid':\n",
    "        search = GridSearchCV(clf, param_grid=param_dict, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
    "    else:\n",
    "        search = RandomizedSearchCV(clf, param_distributions=param_dict, cv=3, n_iter=50)\n",
    "   \n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = search.best_params_\n",
    "    # print(\"Best parameters for MLP: \", best_params)\n",
    "\n",
    "    ## best parameters for MLP: {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'max_iter': 500, 'solver': 'sgd'}\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.474908</td>\n",
       "      <td>0.375470</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.240452</td>\n",
       "      <td>0.751452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.623156</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.701952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet121</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.726575</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.541186</td>\n",
       "      <td>0.691637</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.646214</td>\n",
       "      <td>0.701006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.469985</td>\n",
       "      <td>0.643436</td>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>0.653030</td>\n",
       "      <td>0.693462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.747759</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.583584</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.623185</td>\n",
       "      <td>0.721531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model   XGBoost       MLP  GaussianNB  Adaboost       KNN  \\\n",
       "0     resnet50  0.757914  0.766610    0.474908  0.375470  0.529114   \n",
       "1    resnet101  0.734727  0.742036    0.337184  0.415615  0.623156   \n",
       "2  densenet121  0.764345  0.726575    0.438129  0.541186  0.691637   \n",
       "3  densenet169  0.750967  0.722318    0.429917  0.469985  0.643436   \n",
       "4        vgg16  0.770259  0.747759    0.604003  0.522462  0.583584   \n",
       "\n",
       "   RFClassifier  SVM_linear  SVM_sigmoid   SVM_RBF  \n",
       "0      0.378158    0.785267     0.240452  0.751452  \n",
       "1      0.353422    0.736031     0.274348  0.701952  \n",
       "2      0.375494    0.731575     0.646214  0.701006  \n",
       "3      0.385585    0.716531     0.653030  0.693462  \n",
       "4      0.356552    0.774233     0.623185  0.721531  "
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('BT-large-4c-dataset_results.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking row-wise average of all the data \n",
    "data['average'] = data.drop(\"Model\", axis=1).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBoost         0.744580\n",
       "MLP             0.747059\n",
       "GaussianNB      0.490830\n",
       "Adaboost        0.474236\n",
       "KNN             0.651222\n",
       "RFClassifier    0.420770\n",
       "SVM_linear      0.737906\n",
       "SVM_sigmoid     0.546750\n",
       "SVM_RBF         0.699480\n",
       "average         0.612537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(\"Model\", axis=1).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add coumn-wise average of all the data\n",
    "#data.loc['average'] = data.drop(\"Model\", axis=1).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.474908</td>\n",
       "      <td>0.375470</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.240452</td>\n",
       "      <td>0.751452</td>\n",
       "      <td>0.562149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.623156</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.701952</td>\n",
       "      <td>0.546497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet121</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.726575</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.541186</td>\n",
       "      <td>0.691637</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.646214</td>\n",
       "      <td>0.701006</td>\n",
       "      <td>0.624018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.469985</td>\n",
       "      <td>0.643436</td>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>0.653030</td>\n",
       "      <td>0.693462</td>\n",
       "      <td>0.607248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.747759</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.583584</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.623185</td>\n",
       "      <td>0.721531</td>\n",
       "      <td>0.633730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.753919</td>\n",
       "      <td>0.529857</td>\n",
       "      <td>0.469640</td>\n",
       "      <td>0.587515</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.757488</td>\n",
       "      <td>0.551889</td>\n",
       "      <td>0.711272</td>\n",
       "      <td>0.602797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.740731</td>\n",
       "      <td>0.533478</td>\n",
       "      <td>0.464235</td>\n",
       "      <td>0.637101</td>\n",
       "      <td>0.354683</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.460598</td>\n",
       "      <td>0.669762</td>\n",
       "      <td>0.596662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnext50_32x4d</td>\n",
       "      <td>0.730279</td>\n",
       "      <td>0.688534</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.523486</td>\n",
       "      <td>0.347885</td>\n",
       "      <td>0.662356</td>\n",
       "      <td>0.233913</td>\n",
       "      <td>0.643613</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>0.734357</td>\n",
       "      <td>0.720009</td>\n",
       "      <td>0.396856</td>\n",
       "      <td>0.394528</td>\n",
       "      <td>0.629681</td>\n",
       "      <td>0.342444</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>0.227758</td>\n",
       "      <td>0.713753</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shufflenet_v2_x1_0</td>\n",
       "      <td>0.734401</td>\n",
       "      <td>0.756058</td>\n",
       "      <td>0.546385</td>\n",
       "      <td>0.408590</td>\n",
       "      <td>0.664128</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.753649</td>\n",
       "      <td>0.680268</td>\n",
       "      <td>0.728541</td>\n",
       "      <td>0.628583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>0.699130</td>\n",
       "      <td>0.720044</td>\n",
       "      <td>0.550785</td>\n",
       "      <td>0.359947</td>\n",
       "      <td>0.474278</td>\n",
       "      <td>0.336616</td>\n",
       "      <td>0.724075</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.718422</td>\n",
       "      <td>0.583161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mnasnet0_5</td>\n",
       "      <td>0.711113</td>\n",
       "      <td>0.756710</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.605607</td>\n",
       "      <td>0.337062</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.704675</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.625162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>0.740922</td>\n",
       "      <td>0.778311</td>\n",
       "      <td>0.494005</td>\n",
       "      <td>0.532313</td>\n",
       "      <td>0.661403</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>0.752162</td>\n",
       "      <td>0.613363</td>\n",
       "      <td>0.688947</td>\n",
       "      <td>0.638197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vit_base_patch32_224</td>\n",
       "      <td>0.745541</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.485991</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.630315</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.639235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vit_large_patch16_224</td>\n",
       "      <td>0.753637</td>\n",
       "      <td>0.745676</td>\n",
       "      <td>0.444836</td>\n",
       "      <td>0.509233</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>0.505405</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.598632</td>\n",
       "      <td>0.677358</td>\n",
       "      <td>0.629043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vit_small_patch32_224</td>\n",
       "      <td>0.803164</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.549337</td>\n",
       "      <td>0.519842</td>\n",
       "      <td>0.679366</td>\n",
       "      <td>0.456340</td>\n",
       "      <td>0.760776</td>\n",
       "      <td>0.599472</td>\n",
       "      <td>0.724225</td>\n",
       "      <td>0.651518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deit3_small_patch16_224</td>\n",
       "      <td>0.750585</td>\n",
       "      <td>0.725541</td>\n",
       "      <td>0.504009</td>\n",
       "      <td>0.536741</td>\n",
       "      <td>0.658859</td>\n",
       "      <td>0.378499</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.567225</td>\n",
       "      <td>0.665932</td>\n",
       "      <td>0.611047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vit_base_patch8_224</td>\n",
       "      <td>0.744527</td>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.491719</td>\n",
       "      <td>0.479298</td>\n",
       "      <td>0.704191</td>\n",
       "      <td>0.543143</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.566646</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.639871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vit_tiny_patch16_224</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.763220</td>\n",
       "      <td>0.453747</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>0.690241</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>0.708797</td>\n",
       "      <td>0.551803</td>\n",
       "      <td>0.691268</td>\n",
       "      <td>0.617535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vit_small_patch16_224</td>\n",
       "      <td>0.774932</td>\n",
       "      <td>0.779515</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.512069</td>\n",
       "      <td>0.715422</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.584319</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.650218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vit_base_patch16_384</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>0.747432</td>\n",
       "      <td>0.492955</td>\n",
       "      <td>0.515770</td>\n",
       "      <td>0.749045</td>\n",
       "      <td>0.528537</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.617693</td>\n",
       "      <td>0.696222</td>\n",
       "      <td>0.649339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vit_tiny_patch16_384</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.734436</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>0.455810</td>\n",
       "      <td>0.708981</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.518424</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.598544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vit_small_patch32_384</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>0.771419</td>\n",
       "      <td>0.485850</td>\n",
       "      <td>0.512402</td>\n",
       "      <td>0.722052</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.745088</td>\n",
       "      <td>0.588813</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>0.636176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vit_small_patch16_384</td>\n",
       "      <td>0.699257</td>\n",
       "      <td>0.772150</td>\n",
       "      <td>0.508307</td>\n",
       "      <td>0.500740</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.503193</td>\n",
       "      <td>0.748096</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.671933</td>\n",
       "      <td>0.639122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vit_base_patch32_384</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.767432</td>\n",
       "      <td>0.496328</td>\n",
       "      <td>0.529875</td>\n",
       "      <td>0.703555</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>0.777297</td>\n",
       "      <td>0.644541</td>\n",
       "      <td>0.681181</td>\n",
       "      <td>0.653777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   XGBoost       MLP  GaussianNB  Adaboost  \\\n",
       "0                  resnet50  0.757914  0.766610    0.474908  0.375470   \n",
       "1                 resnet101  0.734727  0.742036    0.337184  0.415615   \n",
       "2               densenet121  0.764345  0.726575    0.438129  0.541186   \n",
       "3               densenet169  0.750967  0.722318    0.429917  0.469985   \n",
       "4                     vgg16  0.770259  0.747759    0.604003  0.522462   \n",
       "5                     vgg19  0.759245  0.753919    0.529857  0.469640   \n",
       "6                   alexnet  0.738231  0.740731    0.533478  0.464235   \n",
       "7           resnext50_32x4d  0.730279  0.688534    0.411075  0.376697   \n",
       "8          resnext101_32x8d  0.734357  0.720009    0.396856  0.394528   \n",
       "9        shufflenet_v2_x1_0  0.734401  0.756058    0.546385  0.408590   \n",
       "10             mobilenet_v2  0.699130  0.720044    0.550785  0.359947   \n",
       "11               mnasnet0_5  0.711113  0.756710    0.645062  0.388312   \n",
       "12     vit_base_patch16_224  0.740922  0.778311    0.494005  0.532313   \n",
       "13     vit_base_patch32_224  0.745541  0.719988    0.485991  0.550373   \n",
       "14    vit_large_patch16_224  0.753637  0.745676    0.444836  0.509233   \n",
       "15    vit_small_patch32_224  0.803164  0.771137    0.549337  0.519842   \n",
       "16  deit3_small_patch16_224  0.750585  0.725541    0.504009  0.536741   \n",
       "17      vit_base_patch8_224  0.744527  0.758919    0.491719  0.479298   \n",
       "18     vit_tiny_patch16_224  0.726475  0.763220    0.453747  0.514764   \n",
       "19    vit_small_patch16_224  0.774932  0.779515    0.531658  0.512069   \n",
       "20     vit_base_patch16_384  0.754515  0.747432    0.492955  0.515770   \n",
       "21     vit_tiny_patch16_384  0.727162  0.734436    0.434370  0.455810   \n",
       "22    vit_small_patch32_384  0.744110  0.771419    0.485850  0.512402   \n",
       "23    vit_small_patch16_384  0.699257  0.772150    0.508307  0.500740   \n",
       "24     vit_base_patch32_384  0.764706  0.767432    0.496328  0.529875   \n",
       "\n",
       "         KNN  RFClassifier  SVM_linear  SVM_sigmoid   SVM_RBF   average  \n",
       "0   0.529114      0.378158    0.785267     0.240452  0.751452  0.562149  \n",
       "1   0.623156      0.353422    0.736031     0.274348  0.701952  0.546497  \n",
       "2   0.691637      0.375494    0.731575     0.646214  0.701006  0.624018  \n",
       "3   0.643436      0.385585    0.716531     0.653030  0.693462  0.607248  \n",
       "4   0.583584      0.356552    0.774233     0.623185  0.721531  0.633730  \n",
       "5   0.587515      0.304348    0.757488     0.551889  0.711272  0.602797  \n",
       "6   0.637101      0.354683    0.771137     0.460598  0.669762  0.596662  \n",
       "7   0.523486      0.347885    0.662356     0.233913  0.643613  0.513093  \n",
       "8   0.629681      0.342444    0.670952     0.227758  0.713753  0.536704  \n",
       "9   0.664128      0.385223    0.753649     0.680268  0.728541  0.628583  \n",
       "10  0.474278      0.336616    0.724075     0.665154  0.718422  0.583161  \n",
       "11  0.605607      0.337062    0.745370     0.704675  0.732544  0.625162  \n",
       "12  0.661403      0.482346    0.752162     0.613363  0.688947  0.638197  \n",
       "13  0.686108      0.514329    0.740405     0.630315  0.680065  0.639235  \n",
       "14  0.686205      0.505405    0.740405     0.598632  0.677358  0.629043  \n",
       "15  0.679366      0.456340    0.760776     0.599472  0.724225  0.651518  \n",
       "16  0.658859      0.378499    0.712036     0.567225  0.665932  0.611047  \n",
       "17  0.704191      0.543143    0.764797     0.566646  0.705601  0.639871  \n",
       "18  0.690241      0.457496    0.708797     0.551803  0.691268  0.617535  \n",
       "19  0.715422      0.523732    0.736022     0.584319  0.694293  0.650218  \n",
       "20  0.749045      0.528537    0.741880     0.617693  0.696222  0.649339  \n",
       "21  0.708981      0.412068    0.691222     0.518424  0.704425  0.598544  \n",
       "22  0.722052      0.437620    0.745088     0.588813  0.718226  0.636176  \n",
       "23  0.722403      0.503193    0.748096     0.626020  0.671933  0.639122  \n",
       "24  0.703555      0.519078    0.777297     0.644541  0.681181  0.653777  "
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vit_base_patch32_384</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.767432</td>\n",
       "      <td>0.496328</td>\n",
       "      <td>0.529875</td>\n",
       "      <td>0.703555</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>0.777297</td>\n",
       "      <td>0.644541</td>\n",
       "      <td>0.681181</td>\n",
       "      <td>0.653777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vit_small_patch32_224</td>\n",
       "      <td>0.803164</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.549337</td>\n",
       "      <td>0.519842</td>\n",
       "      <td>0.679366</td>\n",
       "      <td>0.456340</td>\n",
       "      <td>0.760776</td>\n",
       "      <td>0.599472</td>\n",
       "      <td>0.724225</td>\n",
       "      <td>0.651518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vit_small_patch16_224</td>\n",
       "      <td>0.774932</td>\n",
       "      <td>0.779515</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.512069</td>\n",
       "      <td>0.715422</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.584319</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.650218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vit_base_patch16_384</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>0.747432</td>\n",
       "      <td>0.492955</td>\n",
       "      <td>0.515770</td>\n",
       "      <td>0.749045</td>\n",
       "      <td>0.528537</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.617693</td>\n",
       "      <td>0.696222</td>\n",
       "      <td>0.649339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vit_base_patch8_224</td>\n",
       "      <td>0.744527</td>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.491719</td>\n",
       "      <td>0.479298</td>\n",
       "      <td>0.704191</td>\n",
       "      <td>0.543143</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.566646</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.639871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vit_base_patch32_224</td>\n",
       "      <td>0.745541</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.485991</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.630315</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.639235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vit_small_patch16_384</td>\n",
       "      <td>0.699257</td>\n",
       "      <td>0.772150</td>\n",
       "      <td>0.508307</td>\n",
       "      <td>0.500740</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.503193</td>\n",
       "      <td>0.748096</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.671933</td>\n",
       "      <td>0.639122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>0.740922</td>\n",
       "      <td>0.778311</td>\n",
       "      <td>0.494005</td>\n",
       "      <td>0.532313</td>\n",
       "      <td>0.661403</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>0.752162</td>\n",
       "      <td>0.613363</td>\n",
       "      <td>0.688947</td>\n",
       "      <td>0.638197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vit_small_patch32_384</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>0.771419</td>\n",
       "      <td>0.485850</td>\n",
       "      <td>0.512402</td>\n",
       "      <td>0.722052</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.745088</td>\n",
       "      <td>0.588813</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>0.636176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.747759</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.583584</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.623185</td>\n",
       "      <td>0.721531</td>\n",
       "      <td>0.633730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vit_large_patch16_224</td>\n",
       "      <td>0.753637</td>\n",
       "      <td>0.745676</td>\n",
       "      <td>0.444836</td>\n",
       "      <td>0.509233</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>0.505405</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.598632</td>\n",
       "      <td>0.677358</td>\n",
       "      <td>0.629043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shufflenet_v2_x1_0</td>\n",
       "      <td>0.734401</td>\n",
       "      <td>0.756058</td>\n",
       "      <td>0.546385</td>\n",
       "      <td>0.408590</td>\n",
       "      <td>0.664128</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.753649</td>\n",
       "      <td>0.680268</td>\n",
       "      <td>0.728541</td>\n",
       "      <td>0.628583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mnasnet0_5</td>\n",
       "      <td>0.711113</td>\n",
       "      <td>0.756710</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.605607</td>\n",
       "      <td>0.337062</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.704675</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.625162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet121</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.726575</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.541186</td>\n",
       "      <td>0.691637</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.646214</td>\n",
       "      <td>0.701006</td>\n",
       "      <td>0.624018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vit_tiny_patch16_224</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.763220</td>\n",
       "      <td>0.453747</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>0.690241</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>0.708797</td>\n",
       "      <td>0.551803</td>\n",
       "      <td>0.691268</td>\n",
       "      <td>0.617535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deit3_small_patch16_224</td>\n",
       "      <td>0.750585</td>\n",
       "      <td>0.725541</td>\n",
       "      <td>0.504009</td>\n",
       "      <td>0.536741</td>\n",
       "      <td>0.658859</td>\n",
       "      <td>0.378499</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.567225</td>\n",
       "      <td>0.665932</td>\n",
       "      <td>0.611047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.469985</td>\n",
       "      <td>0.643436</td>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>0.653030</td>\n",
       "      <td>0.693462</td>\n",
       "      <td>0.607248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.753919</td>\n",
       "      <td>0.529857</td>\n",
       "      <td>0.469640</td>\n",
       "      <td>0.587515</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.757488</td>\n",
       "      <td>0.551889</td>\n",
       "      <td>0.711272</td>\n",
       "      <td>0.602797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vit_tiny_patch16_384</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.734436</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>0.455810</td>\n",
       "      <td>0.708981</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.518424</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.598544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.740731</td>\n",
       "      <td>0.533478</td>\n",
       "      <td>0.464235</td>\n",
       "      <td>0.637101</td>\n",
       "      <td>0.354683</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.460598</td>\n",
       "      <td>0.669762</td>\n",
       "      <td>0.596662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>0.699130</td>\n",
       "      <td>0.720044</td>\n",
       "      <td>0.550785</td>\n",
       "      <td>0.359947</td>\n",
       "      <td>0.474278</td>\n",
       "      <td>0.336616</td>\n",
       "      <td>0.724075</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.718422</td>\n",
       "      <td>0.583161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.474908</td>\n",
       "      <td>0.375470</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.240452</td>\n",
       "      <td>0.751452</td>\n",
       "      <td>0.562149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.623156</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.701952</td>\n",
       "      <td>0.546497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>0.734357</td>\n",
       "      <td>0.720009</td>\n",
       "      <td>0.396856</td>\n",
       "      <td>0.394528</td>\n",
       "      <td>0.629681</td>\n",
       "      <td>0.342444</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>0.227758</td>\n",
       "      <td>0.713753</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnext50_32x4d</td>\n",
       "      <td>0.730279</td>\n",
       "      <td>0.688534</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.523486</td>\n",
       "      <td>0.347885</td>\n",
       "      <td>0.662356</td>\n",
       "      <td>0.233913</td>\n",
       "      <td>0.643613</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   XGBoost       MLP  GaussianNB  Adaboost  \\\n",
       "24     vit_base_patch32_384  0.764706  0.767432    0.496328  0.529875   \n",
       "15    vit_small_patch32_224  0.803164  0.771137    0.549337  0.519842   \n",
       "19    vit_small_patch16_224  0.774932  0.779515    0.531658  0.512069   \n",
       "20     vit_base_patch16_384  0.754515  0.747432    0.492955  0.515770   \n",
       "17      vit_base_patch8_224  0.744527  0.758919    0.491719  0.479298   \n",
       "13     vit_base_patch32_224  0.745541  0.719988    0.485991  0.550373   \n",
       "23    vit_small_patch16_384  0.699257  0.772150    0.508307  0.500740   \n",
       "12     vit_base_patch16_224  0.740922  0.778311    0.494005  0.532313   \n",
       "22    vit_small_patch32_384  0.744110  0.771419    0.485850  0.512402   \n",
       "4                     vgg16  0.770259  0.747759    0.604003  0.522462   \n",
       "14    vit_large_patch16_224  0.753637  0.745676    0.444836  0.509233   \n",
       "9        shufflenet_v2_x1_0  0.734401  0.756058    0.546385  0.408590   \n",
       "11               mnasnet0_5  0.711113  0.756710    0.645062  0.388312   \n",
       "2               densenet121  0.764345  0.726575    0.438129  0.541186   \n",
       "18     vit_tiny_patch16_224  0.726475  0.763220    0.453747  0.514764   \n",
       "16  deit3_small_patch16_224  0.750585  0.725541    0.504009  0.536741   \n",
       "3               densenet169  0.750967  0.722318    0.429917  0.469985   \n",
       "5                     vgg19  0.759245  0.753919    0.529857  0.469640   \n",
       "21     vit_tiny_patch16_384  0.727162  0.734436    0.434370  0.455810   \n",
       "6                   alexnet  0.738231  0.740731    0.533478  0.464235   \n",
       "10             mobilenet_v2  0.699130  0.720044    0.550785  0.359947   \n",
       "0                  resnet50  0.757914  0.766610    0.474908  0.375470   \n",
       "1                 resnet101  0.734727  0.742036    0.337184  0.415615   \n",
       "8          resnext101_32x8d  0.734357  0.720009    0.396856  0.394528   \n",
       "7           resnext50_32x4d  0.730279  0.688534    0.411075  0.376697   \n",
       "\n",
       "         KNN  RFClassifier  SVM_linear  SVM_sigmoid   SVM_RBF   average  \n",
       "24  0.703555      0.519078    0.777297     0.644541  0.681181  0.653777  \n",
       "15  0.679366      0.456340    0.760776     0.599472  0.724225  0.651518  \n",
       "19  0.715422      0.523732    0.736022     0.584319  0.694293  0.650218  \n",
       "20  0.749045      0.528537    0.741880     0.617693  0.696222  0.649339  \n",
       "17  0.704191      0.543143    0.764797     0.566646  0.705601  0.639871  \n",
       "13  0.686108      0.514329    0.740405     0.630315  0.680065  0.639235  \n",
       "23  0.722403      0.503193    0.748096     0.626020  0.671933  0.639122  \n",
       "12  0.661403      0.482346    0.752162     0.613363  0.688947  0.638197  \n",
       "22  0.722052      0.437620    0.745088     0.588813  0.718226  0.636176  \n",
       "4   0.583584      0.356552    0.774233     0.623185  0.721531  0.633730  \n",
       "14  0.686205      0.505405    0.740405     0.598632  0.677358  0.629043  \n",
       "9   0.664128      0.385223    0.753649     0.680268  0.728541  0.628583  \n",
       "11  0.605607      0.337062    0.745370     0.704675  0.732544  0.625162  \n",
       "2   0.691637      0.375494    0.731575     0.646214  0.701006  0.624018  \n",
       "18  0.690241      0.457496    0.708797     0.551803  0.691268  0.617535  \n",
       "16  0.658859      0.378499    0.712036     0.567225  0.665932  0.611047  \n",
       "3   0.643436      0.385585    0.716531     0.653030  0.693462  0.607248  \n",
       "5   0.587515      0.304348    0.757488     0.551889  0.711272  0.602797  \n",
       "21  0.708981      0.412068    0.691222     0.518424  0.704425  0.598544  \n",
       "6   0.637101      0.354683    0.771137     0.460598  0.669762  0.596662  \n",
       "10  0.474278      0.336616    0.724075     0.665154  0.718422  0.583161  \n",
       "0   0.529114      0.378158    0.785267     0.240452  0.751452  0.562149  \n",
       "1   0.623156      0.353422    0.736031     0.274348  0.701952  0.546497  \n",
       "8   0.629681      0.342444    0.670952     0.227758  0.713753  0.536704  \n",
       "7   0.523486      0.347885    0.662356     0.233913  0.643613  0.513093  "
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sort the data by average\n",
    "data = data.sort_values(by='average', ascending=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vit_base_patch32_384', 'vit_small_patch32_224', 'vit_small_patch16_224']"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.head(3)['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 performance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_combinations = [\n",
    "                          ['vit_base_patch32_384', 'vit_small_patch32_224'],\n",
    "                          ['vit_base_patch32_384', 'vit_small_patch16_224'],\n",
    "                          ['vit_small_patch32_224', 'vit_small_patch16_224'],\n",
    "                          ['vit_base_patch32_384', 'vit_small_patch32_224', 'vit_small_patch16_224']\n",
    "                          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble vgg16 with Top 2 networks ['vit_base_patch32_384', 'vit_small_patch32_224', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# top_model_combinations = [\n",
    "#                           ['vit_base_patch32_384', 'vit_small_patch32_224'],\n",
    "#                           ['vit_base_patch32_384', 'vgg16'],\n",
    "#                           ['vit_small_patch32_224', 'vgg16'],\n",
    "#                           ['vit_base_patch32_384', 'vit_small_patch32_224', 'vgg16']\n",
    "#                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model List: ['vit_base_patch32_384', 'vit_small_patch32_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 576)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'bootstrap' for estimator MLPClassifier(activation='logistic', max_iter=500, solver='sgd'). Valid parameters are: ['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 854, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\base.py\", line 283, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'bootstrap' for estimator MLPClassifier(activation='logistic', max_iter=500, solver='sgd'). Valid parameters are: ['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[948], line 67\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno of features in X_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Classify the data\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# model_name = ' + '.join(model_list)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[938], line 58\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(X_train, y_train, X_test, y_test, classifier, search_type)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(clf, param_distributions\u001b[38;5;241m=\u001b[39mparam_dict, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n\u001b[0;32m     61\u001b[0m best_params \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'bootstrap' for estimator MLPClassifier(activation='logistic', max_iter=500, solver='sgd'). Valid parameters are: ['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "#columns = ['Model', \"XGBoost\", 'MLP', 'GaussianNB', \"Adaboost\", \"KNN\", \"RFClassifier\", \"SVM_linear\", \"SVM_sigmoid\", \"SVM_RBF\", ]\n",
    "\n",
    "# dataframe = pd.DataFrame(columns=columns)\n",
    "# # add 12 rows to the dataframe with zero values \n",
    "# for model_list in top_model_combinations:\n",
    "#     model_name = ' + '.join(model_list)\n",
    "#     new_row = {'Model': model_name, \"XGBoost\":0, 'MLP': 0, 'GaussianNB': 0, \"Adaboost\": 0, \"KNN\": 0, \"RFClassifier\": 0, \"SVM_linear\": 0, \"SVM_sigmoid\": 0, \"SVM_RBF\": 0} \n",
    "#     dataframe.loc[len(dataframe)] = new_row\n",
    "\n",
    "main_path = 'extracted_features_BT-large-4c'\n",
    "for ml_classifier in ML_CLASSIFIER:\n",
    "    for model_list in top_model_combinations:\n",
    "        print('Model List:', model_list)\n",
    "        ensemble_X_train = []\n",
    "        ensemble_X_test = []\n",
    "\n",
    "        for model in model_list:\n",
    "            sub_dir = os.path.join(main_path, model)\n",
    "            # Load the data\n",
    "            X_train = np.load(os.path.join(sub_dir, 'train_data_array_features.npy'))\n",
    "            y_train = np.load(os.path.join(sub_dir, 'train_data_array_labels.npy'))\n",
    "            X_test = np.load(os.path.join(sub_dir, 'test_data_array_features.npy'))\n",
    "            y_test = np.load(os.path.join(sub_dir, 'test_data_array_labels.npy'))\n",
    "\n",
    "\n",
    "            ## squeeze the dimensions 1 from the features \n",
    "            X_train = np.squeeze(X_train, axis=1)\n",
    "            X_test = np.squeeze(X_test, axis=1)\n",
    "\n",
    "            ## concatenate the features on axis 1\n",
    "            ensemble_X_train.append(X_train)\n",
    "            ensemble_X_test.append(X_test)\n",
    "            \n",
    "\n",
    "        X_train = np.concatenate(ensemble_X_train, axis=1)\n",
    "        y_train = y_train\n",
    "        X_test = np.concatenate(ensemble_X_test, axis=1)\n",
    "        y_test = y_test\n",
    "\n",
    "        ## apply the standard scaler and PCA\n",
    "        scaler = StandardScaler()\n",
    "        X_train_normalized = scaler.fit_transform(X_train)\n",
    "        X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "        # Step 2 & 3: Apply PCA\n",
    "        n_components = int(0.50 * X_train.shape[1])\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train = pca.fit_transform(X_train_normalized)\n",
    "        X_test = pca.transform(X_test_normalized)\n",
    "\n",
    "        ## no of example in each class\n",
    "        print(\"no of example in each class before SMOTE:\", np.bincount(y_train))\n",
    "\n",
    "\n",
    "        ## over sample the data\n",
    "        smote = SMOTE(sampling_strategy='minority')\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        ## no of example in each class\n",
    "        print(\"no of example in each class after SMOTE:\", np.bincount(y_resampled))\n",
    "\n",
    "\n",
    "        print(\"no of features in X_train:\", X_train.shape)\n",
    "\n",
    "        \n",
    "        # Classify the data\n",
    "        accuracy = classify(X_train, y_train, X_test, y_test, ml_classifier)\n",
    "        print('Accuracy:', accuracy)\n",
    "        # model_name = ' + '.join(model_list)\n",
    "        break\n",
    "\n",
    "    #     dataframe.loc[dataframe['Model'] == model_name, ml_classifier] = accuracy\n",
    "\n",
    "    # print(dataframe)\n",
    "    # dataframe.to_csv('BT-large-4c-dataset_results_top_three_normalized_PCA.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[933], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataframe\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224</td>\n",
       "      <td>0.771880</td>\n",
       "      <td>0.767432</td>\n",
       "      <td>0.325871</td>\n",
       "      <td>0.608630</td>\n",
       "      <td>0.698297</td>\n",
       "      <td>0.439245</td>\n",
       "      <td>0.787015</td>\n",
       "      <td>0.682358</td>\n",
       "      <td>0.746419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch16_224</td>\n",
       "      <td>0.748502</td>\n",
       "      <td>0.772297</td>\n",
       "      <td>0.331926</td>\n",
       "      <td>0.607455</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.445041</td>\n",
       "      <td>0.774797</td>\n",
       "      <td>0.657906</td>\n",
       "      <td>0.732488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit_small_patch32_224 + vit_small_patch16_224</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.757759</td>\n",
       "      <td>0.410204</td>\n",
       "      <td>0.545602</td>\n",
       "      <td>0.734597</td>\n",
       "      <td>0.392153</td>\n",
       "      <td>0.719953</td>\n",
       "      <td>0.619690</td>\n",
       "      <td>0.748621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224 +...</td>\n",
       "      <td>0.742297</td>\n",
       "      <td>0.767432</td>\n",
       "      <td>0.328057</td>\n",
       "      <td>0.664034</td>\n",
       "      <td>0.685562</td>\n",
       "      <td>0.408848</td>\n",
       "      <td>0.761419</td>\n",
       "      <td>0.674428</td>\n",
       "      <td>0.739988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model   XGBoost       MLP  \\\n",
       "0       vit_base_patch32_384 + vit_small_patch32_224  0.771880  0.767432   \n",
       "1       vit_base_patch32_384 + vit_small_patch16_224  0.748502  0.772297   \n",
       "2      vit_small_patch32_224 + vit_small_patch16_224  0.753231  0.757759   \n",
       "3  vit_base_patch32_384 + vit_small_patch32_224 +...  0.742297  0.767432   \n",
       "\n",
       "   GaussianNB  Adaboost       KNN  RFClassifier  SVM_linear  SVM_sigmoid  \\\n",
       "0    0.325871  0.608630  0.698297      0.439245    0.787015     0.682358   \n",
       "1    0.331926  0.607455  0.689115      0.445041    0.774797     0.657906   \n",
       "2    0.410204  0.545602  0.734597      0.392153    0.719953     0.619690   \n",
       "3    0.328057  0.664034  0.685562      0.408848    0.761419     0.674428   \n",
       "\n",
       "    SVM_RBF  \n",
       "0  0.746419  \n",
       "1  0.732488  \n",
       "2  0.748621  \n",
       "3  0.739988  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224</td>\n",
       "      <td>0.772150</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.268695</td>\n",
       "      <td>0.539740</td>\n",
       "      <td>0.742775</td>\n",
       "      <td>0.444307</td>\n",
       "      <td>0.800811</td>\n",
       "      <td>0.682358</td>\n",
       "      <td>0.746419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch16_224</td>\n",
       "      <td>0.752623</td>\n",
       "      <td>0.769932</td>\n",
       "      <td>0.281045</td>\n",
       "      <td>0.515953</td>\n",
       "      <td>0.730466</td>\n",
       "      <td>0.449480</td>\n",
       "      <td>0.787297</td>\n",
       "      <td>0.670613</td>\n",
       "      <td>0.732488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit_small_patch32_224 + vit_small_patch16_224</td>\n",
       "      <td>0.756610</td>\n",
       "      <td>0.769189</td>\n",
       "      <td>0.309645</td>\n",
       "      <td>0.494572</td>\n",
       "      <td>0.747957</td>\n",
       "      <td>0.455855</td>\n",
       "      <td>0.753919</td>\n",
       "      <td>0.620195</td>\n",
       "      <td>0.746002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224 +...</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.774189</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.546492</td>\n",
       "      <td>0.740222</td>\n",
       "      <td>0.381939</td>\n",
       "      <td>0.769054</td>\n",
       "      <td>0.653766</td>\n",
       "      <td>0.734988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model   XGBoost       MLP  \\\n",
       "0       vit_base_patch32_384 + vit_small_patch32_224  0.772150  0.770259   \n",
       "1       vit_base_patch32_384 + vit_small_patch16_224  0.752623  0.769932   \n",
       "2      vit_small_patch32_224 + vit_small_patch16_224  0.756610  0.769189   \n",
       "3  vit_base_patch32_384 + vit_small_patch32_224 +...  0.756554  0.774189   \n",
       "\n",
       "   GaussianNB  Adaboost       KNN  RFClassifier  SVM_linear  SVM_sigmoid  \\\n",
       "0    0.268695  0.539740  0.742775      0.444307    0.800811     0.682358   \n",
       "1    0.281045  0.515953  0.730466      0.449480    0.787297     0.670613   \n",
       "2    0.309645  0.494572  0.747957      0.455855    0.753919     0.620195   \n",
       "3    0.249423  0.546492  0.740222      0.381939    0.769054     0.653766   \n",
       "\n",
       "    SVM_RBF  \n",
       "0  0.746419  \n",
       "1  0.732488  \n",
       "2  0.746002  \n",
       "3  0.734988  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
