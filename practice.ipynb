{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "## svm\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_CLASSIFIER = ['MLP', 'GaussianNB', \"Adaboost\", \"KNN\", \"RFClassifier\", \"SVM_linear\", \"SVM_sigmoid\", \"SVM_RBF\", \"XGBoost\"] # \"ELM\"\n",
    "\n",
    "def classify(X_train, y_train, X_test, y_test, classifier, search_type='grid'):\n",
    "    \"\"\"\n",
    "    Classify the data using a Random Forest Classifier\n",
    "    :param X_train: Training data\n",
    "    :param y_train: Training labels\n",
    "    :param X_test: Testing data\n",
    "    :param y_test: Testing labels\n",
    "    :param search_type: Type of search to perform\n",
    "    :return: Accuracy of the classifier\n",
    "    \"\"\"\n",
    "    # Create a Random Forest Classifier\n",
    "    #clf = RandomForestClassifier()\n",
    "\n",
    "    if classifier == \"MLP\":\n",
    "        # clf = MLPClassifier(hidden_layer_sizes=(100,100, 50), max_iter=1000) ### uncomment if the performance is not good with below hyperparameter\n",
    "        clf = MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 22), max_iter=1000, momentum=0.99, solver='sgd')\n",
    "    elif classifier == \"GaussianNB\": ### {'priors': None, 'var_smoothing': 1e-05}\n",
    "        clf = GaussianNB(priors=None, var_smoothing= 1e-05) ### Often, the default parameters work well for many datasets.\n",
    "    elif classifier == \"Adaboost\":\n",
    "        dtc = DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='entropy', max_depth=10, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=2, min_samples_split=2, splitter='best')\n",
    "        clf = AdaBoostClassifier(estimator=dtc, n_estimators=200, random_state=0, learning_rate=1) ###{'learning_rate': 1, 'n_estimators': 200}\n",
    "        \n",
    "    elif classifier == \"KNN\":\n",
    "        clf = KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='euclidean', n_jobs=-1,  n_neighbors=1, p=1, weights='uniform')  \n",
    "    elif classifier == \"RFClassifier\": ### \n",
    "        clf = RandomForestClassifier(bootstrap = False, criterion = 'entropy', max_depth = None, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 500, oob_score = False, random_state = 42)\n",
    "    elif classifier == \"SVM_linear\": ##\n",
    "        clf = SVC(kernel='linear', C = 0.1, class_weight = 'balanced', random_state=42, tol=0.001 )\n",
    "    elif classifier == \"SVM_sigmoid\": ###\n",
    "        clf = SVC(kernel='sigmoid', C=1, cache_size=200.0, class_weight='balanced', coef0=0.0, gamma='scale', probability=True, random_state=42, shrinking=True, tol=0.0001)\n",
    "    elif classifier == \"SVM_RBF\": \n",
    "        clf = SVC(C=10, cache_size = 200, class_weight = None, gamma = 'scale', kernel = 'rbf', max_iter = -1, probability = True, shrinking = True, tol = 0.001)\n",
    "    elif classifier == \"XGBoost\": #'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.7\n",
    "        clf = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=3,subsample=0.7)\n",
    "    else:\n",
    "        print(\"Invalid classifier\")\n",
    "        return None\n",
    "        # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.474908</td>\n",
       "      <td>0.375470</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.240452</td>\n",
       "      <td>0.751452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.623156</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.701952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet121</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.726575</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.541186</td>\n",
       "      <td>0.691637</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.646214</td>\n",
       "      <td>0.701006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.469985</td>\n",
       "      <td>0.643436</td>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>0.653030</td>\n",
       "      <td>0.693462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.747759</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.583584</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.623185</td>\n",
       "      <td>0.721531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model   XGBoost       MLP  GaussianNB  Adaboost       KNN  \\\n",
       "0     resnet50  0.757914  0.766610    0.474908  0.375470  0.529114   \n",
       "1    resnet101  0.734727  0.742036    0.337184  0.415615  0.623156   \n",
       "2  densenet121  0.764345  0.726575    0.438129  0.541186  0.691637   \n",
       "3  densenet169  0.750967  0.722318    0.429917  0.469985  0.643436   \n",
       "4        vgg16  0.770259  0.747759    0.604003  0.522462  0.583584   \n",
       "\n",
       "   RFClassifier  SVM_linear  SVM_sigmoid   SVM_RBF  \n",
       "0      0.378158    0.785267     0.240452  0.751452  \n",
       "1      0.353422    0.736031     0.274348  0.701952  \n",
       "2      0.375494    0.731575     0.646214  0.701006  \n",
       "3      0.385585    0.716531     0.653030  0.693462  \n",
       "4      0.356552    0.774233     0.623185  0.721531  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('BT-large-4c-dataset_results.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking row-wise average of all the data \n",
    "data['average'] = data.drop(\"Model\", axis=1).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBoost         0.744580\n",
       "MLP             0.747059\n",
       "GaussianNB      0.490830\n",
       "Adaboost        0.474236\n",
       "KNN             0.651222\n",
       "RFClassifier    0.420770\n",
       "SVM_linear      0.737906\n",
       "SVM_sigmoid     0.546750\n",
       "SVM_RBF         0.699480\n",
       "average         0.612537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(\"Model\", axis=1).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add coumn-wise average of all the data\n",
    "#data.loc['average'] = data.drop(\"Model\", axis=1).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.474908</td>\n",
       "      <td>0.375470</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.240452</td>\n",
       "      <td>0.751452</td>\n",
       "      <td>0.562149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.623156</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.701952</td>\n",
       "      <td>0.546497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet121</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.726575</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.541186</td>\n",
       "      <td>0.691637</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.646214</td>\n",
       "      <td>0.701006</td>\n",
       "      <td>0.624018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.469985</td>\n",
       "      <td>0.643436</td>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>0.653030</td>\n",
       "      <td>0.693462</td>\n",
       "      <td>0.607248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.747759</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.583584</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.623185</td>\n",
       "      <td>0.721531</td>\n",
       "      <td>0.633730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.753919</td>\n",
       "      <td>0.529857</td>\n",
       "      <td>0.469640</td>\n",
       "      <td>0.587515</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.757488</td>\n",
       "      <td>0.551889</td>\n",
       "      <td>0.711272</td>\n",
       "      <td>0.602797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.740731</td>\n",
       "      <td>0.533478</td>\n",
       "      <td>0.464235</td>\n",
       "      <td>0.637101</td>\n",
       "      <td>0.354683</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.460598</td>\n",
       "      <td>0.669762</td>\n",
       "      <td>0.596662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnext50_32x4d</td>\n",
       "      <td>0.730279</td>\n",
       "      <td>0.688534</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.523486</td>\n",
       "      <td>0.347885</td>\n",
       "      <td>0.662356</td>\n",
       "      <td>0.233913</td>\n",
       "      <td>0.643613</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>0.734357</td>\n",
       "      <td>0.720009</td>\n",
       "      <td>0.396856</td>\n",
       "      <td>0.394528</td>\n",
       "      <td>0.629681</td>\n",
       "      <td>0.342444</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>0.227758</td>\n",
       "      <td>0.713753</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shufflenet_v2_x1_0</td>\n",
       "      <td>0.734401</td>\n",
       "      <td>0.756058</td>\n",
       "      <td>0.546385</td>\n",
       "      <td>0.408590</td>\n",
       "      <td>0.664128</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.753649</td>\n",
       "      <td>0.680268</td>\n",
       "      <td>0.728541</td>\n",
       "      <td>0.628583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>0.699130</td>\n",
       "      <td>0.720044</td>\n",
       "      <td>0.550785</td>\n",
       "      <td>0.359947</td>\n",
       "      <td>0.474278</td>\n",
       "      <td>0.336616</td>\n",
       "      <td>0.724075</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.718422</td>\n",
       "      <td>0.583161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mnasnet0_5</td>\n",
       "      <td>0.711113</td>\n",
       "      <td>0.756710</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.605607</td>\n",
       "      <td>0.337062</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.704675</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.625162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>0.740922</td>\n",
       "      <td>0.778311</td>\n",
       "      <td>0.494005</td>\n",
       "      <td>0.532313</td>\n",
       "      <td>0.661403</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>0.752162</td>\n",
       "      <td>0.613363</td>\n",
       "      <td>0.688947</td>\n",
       "      <td>0.638197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vit_base_patch32_224</td>\n",
       "      <td>0.745541</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.485991</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.630315</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.639235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vit_large_patch16_224</td>\n",
       "      <td>0.753637</td>\n",
       "      <td>0.745676</td>\n",
       "      <td>0.444836</td>\n",
       "      <td>0.509233</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>0.505405</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.598632</td>\n",
       "      <td>0.677358</td>\n",
       "      <td>0.629043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vit_small_patch32_224</td>\n",
       "      <td>0.803164</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.549337</td>\n",
       "      <td>0.519842</td>\n",
       "      <td>0.679366</td>\n",
       "      <td>0.456340</td>\n",
       "      <td>0.760776</td>\n",
       "      <td>0.599472</td>\n",
       "      <td>0.724225</td>\n",
       "      <td>0.651518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deit3_small_patch16_224</td>\n",
       "      <td>0.750585</td>\n",
       "      <td>0.725541</td>\n",
       "      <td>0.504009</td>\n",
       "      <td>0.536741</td>\n",
       "      <td>0.658859</td>\n",
       "      <td>0.378499</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.567225</td>\n",
       "      <td>0.665932</td>\n",
       "      <td>0.611047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vit_base_patch8_224</td>\n",
       "      <td>0.744527</td>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.491719</td>\n",
       "      <td>0.479298</td>\n",
       "      <td>0.704191</td>\n",
       "      <td>0.543143</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.566646</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.639871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vit_tiny_patch16_224</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.763220</td>\n",
       "      <td>0.453747</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>0.690241</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>0.708797</td>\n",
       "      <td>0.551803</td>\n",
       "      <td>0.691268</td>\n",
       "      <td>0.617535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vit_small_patch16_224</td>\n",
       "      <td>0.774932</td>\n",
       "      <td>0.779515</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.512069</td>\n",
       "      <td>0.715422</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.584319</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.650218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vit_base_patch16_384</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>0.747432</td>\n",
       "      <td>0.492955</td>\n",
       "      <td>0.515770</td>\n",
       "      <td>0.749045</td>\n",
       "      <td>0.528537</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.617693</td>\n",
       "      <td>0.696222</td>\n",
       "      <td>0.649339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vit_tiny_patch16_384</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.734436</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>0.455810</td>\n",
       "      <td>0.708981</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.518424</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.598544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vit_small_patch32_384</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>0.771419</td>\n",
       "      <td>0.485850</td>\n",
       "      <td>0.512402</td>\n",
       "      <td>0.722052</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.745088</td>\n",
       "      <td>0.588813</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>0.636176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vit_small_patch16_384</td>\n",
       "      <td>0.699257</td>\n",
       "      <td>0.772150</td>\n",
       "      <td>0.508307</td>\n",
       "      <td>0.500740</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.503193</td>\n",
       "      <td>0.748096</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.671933</td>\n",
       "      <td>0.639122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vit_base_patch32_384</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.767432</td>\n",
       "      <td>0.496328</td>\n",
       "      <td>0.529875</td>\n",
       "      <td>0.703555</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>0.777297</td>\n",
       "      <td>0.644541</td>\n",
       "      <td>0.681181</td>\n",
       "      <td>0.653777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   XGBoost       MLP  GaussianNB  Adaboost  \\\n",
       "0                  resnet50  0.757914  0.766610    0.474908  0.375470   \n",
       "1                 resnet101  0.734727  0.742036    0.337184  0.415615   \n",
       "2               densenet121  0.764345  0.726575    0.438129  0.541186   \n",
       "3               densenet169  0.750967  0.722318    0.429917  0.469985   \n",
       "4                     vgg16  0.770259  0.747759    0.604003  0.522462   \n",
       "5                     vgg19  0.759245  0.753919    0.529857  0.469640   \n",
       "6                   alexnet  0.738231  0.740731    0.533478  0.464235   \n",
       "7           resnext50_32x4d  0.730279  0.688534    0.411075  0.376697   \n",
       "8          resnext101_32x8d  0.734357  0.720009    0.396856  0.394528   \n",
       "9        shufflenet_v2_x1_0  0.734401  0.756058    0.546385  0.408590   \n",
       "10             mobilenet_v2  0.699130  0.720044    0.550785  0.359947   \n",
       "11               mnasnet0_5  0.711113  0.756710    0.645062  0.388312   \n",
       "12     vit_base_patch16_224  0.740922  0.778311    0.494005  0.532313   \n",
       "13     vit_base_patch32_224  0.745541  0.719988    0.485991  0.550373   \n",
       "14    vit_large_patch16_224  0.753637  0.745676    0.444836  0.509233   \n",
       "15    vit_small_patch32_224  0.803164  0.771137    0.549337  0.519842   \n",
       "16  deit3_small_patch16_224  0.750585  0.725541    0.504009  0.536741   \n",
       "17      vit_base_patch8_224  0.744527  0.758919    0.491719  0.479298   \n",
       "18     vit_tiny_patch16_224  0.726475  0.763220    0.453747  0.514764   \n",
       "19    vit_small_patch16_224  0.774932  0.779515    0.531658  0.512069   \n",
       "20     vit_base_patch16_384  0.754515  0.747432    0.492955  0.515770   \n",
       "21     vit_tiny_patch16_384  0.727162  0.734436    0.434370  0.455810   \n",
       "22    vit_small_patch32_384  0.744110  0.771419    0.485850  0.512402   \n",
       "23    vit_small_patch16_384  0.699257  0.772150    0.508307  0.500740   \n",
       "24     vit_base_patch32_384  0.764706  0.767432    0.496328  0.529875   \n",
       "\n",
       "         KNN  RFClassifier  SVM_linear  SVM_sigmoid   SVM_RBF   average  \n",
       "0   0.529114      0.378158    0.785267     0.240452  0.751452  0.562149  \n",
       "1   0.623156      0.353422    0.736031     0.274348  0.701952  0.546497  \n",
       "2   0.691637      0.375494    0.731575     0.646214  0.701006  0.624018  \n",
       "3   0.643436      0.385585    0.716531     0.653030  0.693462  0.607248  \n",
       "4   0.583584      0.356552    0.774233     0.623185  0.721531  0.633730  \n",
       "5   0.587515      0.304348    0.757488     0.551889  0.711272  0.602797  \n",
       "6   0.637101      0.354683    0.771137     0.460598  0.669762  0.596662  \n",
       "7   0.523486      0.347885    0.662356     0.233913  0.643613  0.513093  \n",
       "8   0.629681      0.342444    0.670952     0.227758  0.713753  0.536704  \n",
       "9   0.664128      0.385223    0.753649     0.680268  0.728541  0.628583  \n",
       "10  0.474278      0.336616    0.724075     0.665154  0.718422  0.583161  \n",
       "11  0.605607      0.337062    0.745370     0.704675  0.732544  0.625162  \n",
       "12  0.661403      0.482346    0.752162     0.613363  0.688947  0.638197  \n",
       "13  0.686108      0.514329    0.740405     0.630315  0.680065  0.639235  \n",
       "14  0.686205      0.505405    0.740405     0.598632  0.677358  0.629043  \n",
       "15  0.679366      0.456340    0.760776     0.599472  0.724225  0.651518  \n",
       "16  0.658859      0.378499    0.712036     0.567225  0.665932  0.611047  \n",
       "17  0.704191      0.543143    0.764797     0.566646  0.705601  0.639871  \n",
       "18  0.690241      0.457496    0.708797     0.551803  0.691268  0.617535  \n",
       "19  0.715422      0.523732    0.736022     0.584319  0.694293  0.650218  \n",
       "20  0.749045      0.528537    0.741880     0.617693  0.696222  0.649339  \n",
       "21  0.708981      0.412068    0.691222     0.518424  0.704425  0.598544  \n",
       "22  0.722052      0.437620    0.745088     0.588813  0.718226  0.636176  \n",
       "23  0.722403      0.503193    0.748096     0.626020  0.671933  0.639122  \n",
       "24  0.703555      0.519078    0.777297     0.644541  0.681181  0.653777  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vit_base_patch32_384</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.767432</td>\n",
       "      <td>0.496328</td>\n",
       "      <td>0.529875</td>\n",
       "      <td>0.703555</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>0.777297</td>\n",
       "      <td>0.644541</td>\n",
       "      <td>0.681181</td>\n",
       "      <td>0.653777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vit_small_patch32_224</td>\n",
       "      <td>0.803164</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.549337</td>\n",
       "      <td>0.519842</td>\n",
       "      <td>0.679366</td>\n",
       "      <td>0.456340</td>\n",
       "      <td>0.760776</td>\n",
       "      <td>0.599472</td>\n",
       "      <td>0.724225</td>\n",
       "      <td>0.651518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vit_small_patch16_224</td>\n",
       "      <td>0.774932</td>\n",
       "      <td>0.779515</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>0.512069</td>\n",
       "      <td>0.715422</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.736022</td>\n",
       "      <td>0.584319</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.650218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vit_base_patch16_384</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>0.747432</td>\n",
       "      <td>0.492955</td>\n",
       "      <td>0.515770</td>\n",
       "      <td>0.749045</td>\n",
       "      <td>0.528537</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.617693</td>\n",
       "      <td>0.696222</td>\n",
       "      <td>0.649339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vit_base_patch8_224</td>\n",
       "      <td>0.744527</td>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.491719</td>\n",
       "      <td>0.479298</td>\n",
       "      <td>0.704191</td>\n",
       "      <td>0.543143</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.566646</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.639871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vit_base_patch32_224</td>\n",
       "      <td>0.745541</td>\n",
       "      <td>0.719988</td>\n",
       "      <td>0.485991</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.630315</td>\n",
       "      <td>0.680065</td>\n",
       "      <td>0.639235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vit_small_patch16_384</td>\n",
       "      <td>0.699257</td>\n",
       "      <td>0.772150</td>\n",
       "      <td>0.508307</td>\n",
       "      <td>0.500740</td>\n",
       "      <td>0.722403</td>\n",
       "      <td>0.503193</td>\n",
       "      <td>0.748096</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.671933</td>\n",
       "      <td>0.639122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vit_base_patch16_224</td>\n",
       "      <td>0.740922</td>\n",
       "      <td>0.778311</td>\n",
       "      <td>0.494005</td>\n",
       "      <td>0.532313</td>\n",
       "      <td>0.661403</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>0.752162</td>\n",
       "      <td>0.613363</td>\n",
       "      <td>0.688947</td>\n",
       "      <td>0.638197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vit_small_patch32_384</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>0.771419</td>\n",
       "      <td>0.485850</td>\n",
       "      <td>0.512402</td>\n",
       "      <td>0.722052</td>\n",
       "      <td>0.437620</td>\n",
       "      <td>0.745088</td>\n",
       "      <td>0.588813</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>0.636176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.747759</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.522462</td>\n",
       "      <td>0.583584</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.623185</td>\n",
       "      <td>0.721531</td>\n",
       "      <td>0.633730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vit_large_patch16_224</td>\n",
       "      <td>0.753637</td>\n",
       "      <td>0.745676</td>\n",
       "      <td>0.444836</td>\n",
       "      <td>0.509233</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>0.505405</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.598632</td>\n",
       "      <td>0.677358</td>\n",
       "      <td>0.629043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shufflenet_v2_x1_0</td>\n",
       "      <td>0.734401</td>\n",
       "      <td>0.756058</td>\n",
       "      <td>0.546385</td>\n",
       "      <td>0.408590</td>\n",
       "      <td>0.664128</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.753649</td>\n",
       "      <td>0.680268</td>\n",
       "      <td>0.728541</td>\n",
       "      <td>0.628583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mnasnet0_5</td>\n",
       "      <td>0.711113</td>\n",
       "      <td>0.756710</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.605607</td>\n",
       "      <td>0.337062</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.704675</td>\n",
       "      <td>0.732544</td>\n",
       "      <td>0.625162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>densenet121</td>\n",
       "      <td>0.764345</td>\n",
       "      <td>0.726575</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.541186</td>\n",
       "      <td>0.691637</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.731575</td>\n",
       "      <td>0.646214</td>\n",
       "      <td>0.701006</td>\n",
       "      <td>0.624018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vit_tiny_patch16_224</td>\n",
       "      <td>0.726475</td>\n",
       "      <td>0.763220</td>\n",
       "      <td>0.453747</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>0.690241</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>0.708797</td>\n",
       "      <td>0.551803</td>\n",
       "      <td>0.691268</td>\n",
       "      <td>0.617535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deit3_small_patch16_224</td>\n",
       "      <td>0.750585</td>\n",
       "      <td>0.725541</td>\n",
       "      <td>0.504009</td>\n",
       "      <td>0.536741</td>\n",
       "      <td>0.658859</td>\n",
       "      <td>0.378499</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.567225</td>\n",
       "      <td>0.665932</td>\n",
       "      <td>0.611047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.722318</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.469985</td>\n",
       "      <td>0.643436</td>\n",
       "      <td>0.385585</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>0.653030</td>\n",
       "      <td>0.693462</td>\n",
       "      <td>0.607248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg19</td>\n",
       "      <td>0.759245</td>\n",
       "      <td>0.753919</td>\n",
       "      <td>0.529857</td>\n",
       "      <td>0.469640</td>\n",
       "      <td>0.587515</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.757488</td>\n",
       "      <td>0.551889</td>\n",
       "      <td>0.711272</td>\n",
       "      <td>0.602797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vit_tiny_patch16_384</td>\n",
       "      <td>0.727162</td>\n",
       "      <td>0.734436</td>\n",
       "      <td>0.434370</td>\n",
       "      <td>0.455810</td>\n",
       "      <td>0.708981</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.518424</td>\n",
       "      <td>0.704425</td>\n",
       "      <td>0.598544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.740731</td>\n",
       "      <td>0.533478</td>\n",
       "      <td>0.464235</td>\n",
       "      <td>0.637101</td>\n",
       "      <td>0.354683</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.460598</td>\n",
       "      <td>0.669762</td>\n",
       "      <td>0.596662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>0.699130</td>\n",
       "      <td>0.720044</td>\n",
       "      <td>0.550785</td>\n",
       "      <td>0.359947</td>\n",
       "      <td>0.474278</td>\n",
       "      <td>0.336616</td>\n",
       "      <td>0.724075</td>\n",
       "      <td>0.665154</td>\n",
       "      <td>0.718422</td>\n",
       "      <td>0.583161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.757914</td>\n",
       "      <td>0.766610</td>\n",
       "      <td>0.474908</td>\n",
       "      <td>0.375470</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.378158</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.240452</td>\n",
       "      <td>0.751452</td>\n",
       "      <td>0.562149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet101</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.742036</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.623156</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>0.736031</td>\n",
       "      <td>0.274348</td>\n",
       "      <td>0.701952</td>\n",
       "      <td>0.546497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnext101_32x8d</td>\n",
       "      <td>0.734357</td>\n",
       "      <td>0.720009</td>\n",
       "      <td>0.396856</td>\n",
       "      <td>0.394528</td>\n",
       "      <td>0.629681</td>\n",
       "      <td>0.342444</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>0.227758</td>\n",
       "      <td>0.713753</td>\n",
       "      <td>0.536704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnext50_32x4d</td>\n",
       "      <td>0.730279</td>\n",
       "      <td>0.688534</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>0.376697</td>\n",
       "      <td>0.523486</td>\n",
       "      <td>0.347885</td>\n",
       "      <td>0.662356</td>\n",
       "      <td>0.233913</td>\n",
       "      <td>0.643613</td>\n",
       "      <td>0.513093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   XGBoost       MLP  GaussianNB  Adaboost  \\\n",
       "24     vit_base_patch32_384  0.764706  0.767432    0.496328  0.529875   \n",
       "15    vit_small_patch32_224  0.803164  0.771137    0.549337  0.519842   \n",
       "19    vit_small_patch16_224  0.774932  0.779515    0.531658  0.512069   \n",
       "20     vit_base_patch16_384  0.754515  0.747432    0.492955  0.515770   \n",
       "17      vit_base_patch8_224  0.744527  0.758919    0.491719  0.479298   \n",
       "13     vit_base_patch32_224  0.745541  0.719988    0.485991  0.550373   \n",
       "23    vit_small_patch16_384  0.699257  0.772150    0.508307  0.500740   \n",
       "12     vit_base_patch16_224  0.740922  0.778311    0.494005  0.532313   \n",
       "22    vit_small_patch32_384  0.744110  0.771419    0.485850  0.512402   \n",
       "4                     vgg16  0.770259  0.747759    0.604003  0.522462   \n",
       "14    vit_large_patch16_224  0.753637  0.745676    0.444836  0.509233   \n",
       "9        shufflenet_v2_x1_0  0.734401  0.756058    0.546385  0.408590   \n",
       "11               mnasnet0_5  0.711113  0.756710    0.645062  0.388312   \n",
       "2               densenet121  0.764345  0.726575    0.438129  0.541186   \n",
       "18     vit_tiny_patch16_224  0.726475  0.763220    0.453747  0.514764   \n",
       "16  deit3_small_patch16_224  0.750585  0.725541    0.504009  0.536741   \n",
       "3               densenet169  0.750967  0.722318    0.429917  0.469985   \n",
       "5                     vgg19  0.759245  0.753919    0.529857  0.469640   \n",
       "21     vit_tiny_patch16_384  0.727162  0.734436    0.434370  0.455810   \n",
       "6                   alexnet  0.738231  0.740731    0.533478  0.464235   \n",
       "10             mobilenet_v2  0.699130  0.720044    0.550785  0.359947   \n",
       "0                  resnet50  0.757914  0.766610    0.474908  0.375470   \n",
       "1                 resnet101  0.734727  0.742036    0.337184  0.415615   \n",
       "8          resnext101_32x8d  0.734357  0.720009    0.396856  0.394528   \n",
       "7           resnext50_32x4d  0.730279  0.688534    0.411075  0.376697   \n",
       "\n",
       "         KNN  RFClassifier  SVM_linear  SVM_sigmoid   SVM_RBF   average  \n",
       "24  0.703555      0.519078    0.777297     0.644541  0.681181  0.653777  \n",
       "15  0.679366      0.456340    0.760776     0.599472  0.724225  0.651518  \n",
       "19  0.715422      0.523732    0.736022     0.584319  0.694293  0.650218  \n",
       "20  0.749045      0.528537    0.741880     0.617693  0.696222  0.649339  \n",
       "17  0.704191      0.543143    0.764797     0.566646  0.705601  0.639871  \n",
       "13  0.686108      0.514329    0.740405     0.630315  0.680065  0.639235  \n",
       "23  0.722403      0.503193    0.748096     0.626020  0.671933  0.639122  \n",
       "12  0.661403      0.482346    0.752162     0.613363  0.688947  0.638197  \n",
       "22  0.722052      0.437620    0.745088     0.588813  0.718226  0.636176  \n",
       "4   0.583584      0.356552    0.774233     0.623185  0.721531  0.633730  \n",
       "14  0.686205      0.505405    0.740405     0.598632  0.677358  0.629043  \n",
       "9   0.664128      0.385223    0.753649     0.680268  0.728541  0.628583  \n",
       "11  0.605607      0.337062    0.745370     0.704675  0.732544  0.625162  \n",
       "2   0.691637      0.375494    0.731575     0.646214  0.701006  0.624018  \n",
       "18  0.690241      0.457496    0.708797     0.551803  0.691268  0.617535  \n",
       "16  0.658859      0.378499    0.712036     0.567225  0.665932  0.611047  \n",
       "3   0.643436      0.385585    0.716531     0.653030  0.693462  0.607248  \n",
       "5   0.587515      0.304348    0.757488     0.551889  0.711272  0.602797  \n",
       "21  0.708981      0.412068    0.691222     0.518424  0.704425  0.598544  \n",
       "6   0.637101      0.354683    0.771137     0.460598  0.669762  0.596662  \n",
       "10  0.474278      0.336616    0.724075     0.665154  0.718422  0.583161  \n",
       "0   0.529114      0.378158    0.785267     0.240452  0.751452  0.562149  \n",
       "1   0.623156      0.353422    0.736031     0.274348  0.701952  0.546497  \n",
       "8   0.629681      0.342444    0.670952     0.227758  0.713753  0.536704  \n",
       "7   0.523486      0.347885    0.662356     0.233913  0.643613  0.513093  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sort the data by average\n",
    "data = data.sort_values(by='average', ascending=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vit_base_patch32_384', 'vit_small_patch32_224', 'vit_small_patch16_224']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.head(3)['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 performance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_combinations = [\n",
    "                          ['vit_base_patch32_384', 'vit_small_patch32_224'],\n",
    "                          ['vit_base_patch32_384', 'vit_small_patch16_224'],\n",
    "                          ['vit_small_patch32_224', 'vit_small_patch16_224'],\n",
    "                          ['vit_base_patch32_384', 'vit_small_patch32_224', 'vit_small_patch16_224']\n",
    "                          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble vgg16 with Top 2 networks ['vit_base_patch32_384', 'vit_small_patch32_224', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# top_model_combinations = [\n",
    "#                           ['vit_base_patch32_384', 'vit_small_patch32_224'],\n",
    "#                           ['vit_base_patch32_384', 'vgg16'],\n",
    "#                           ['vit_small_patch32_224', 'vgg16'],\n",
    "#                           ['vit_base_patch32_384', 'vit_small_patch32_224', 'vgg16']\n",
    "#                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model List: ['vit_base_patch32_384', 'vit_small_patch32_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 576)\n",
      "Accuracy: 0.7724324324324324\n",
      "Model List: ['vit_base_patch32_384', 'vit_small_patch16_224']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_30684\\3935780486.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7724324324324324' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dataframe.loc[dataframe['Model'] == model_name, ml_classifier] = accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 576)\n",
      "Accuracy: 0.7672972972972972\n",
      "Model List: ['vit_small_patch32_224', 'vit_small_patch16_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 384)\n",
      "Accuracy: 0.7512837837837838\n",
      "Model List: ['vit_base_patch32_384', 'vit_small_patch32_224', 'vit_small_patch16_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 768)\n",
      "Accuracy: 0.7672972972972972\n",
      "                                               Model  XGBoost       MLP  \\\n",
      "0       vit_base_patch32_384 + vit_small_patch32_224        0  0.772432   \n",
      "1       vit_base_patch32_384 + vit_small_patch16_224        0  0.767297   \n",
      "2      vit_small_patch32_224 + vit_small_patch16_224        0  0.751284   \n",
      "3  vit_base_patch32_384 + vit_small_patch32_224 +...        0  0.767297   \n",
      "\n",
      "   GaussianNB  Adaboost  KNN  RFClassifier  SVM_linear  SVM_sigmoid  SVM_RBF  \n",
      "0           0         0    0             0           0            0        0  \n",
      "1           0         0    0             0           0            0        0  \n",
      "2           0         0    0             0           0            0        0  \n",
      "3           0         0    0             0           0            0        0  \n",
      "Model List: ['vit_base_patch32_384', 'vit_small_patch32_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 576)\n",
      "Accuracy: 0.347588271501315\n",
      "Model List: ['vit_base_patch32_384', 'vit_small_patch16_224']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_30684\\3935780486.py:71: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.347588271501315' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dataframe.loc[dataframe['Model'] == model_name, ml_classifier] = accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 576)\n",
      "Accuracy: 0.33880462760897545\n",
      "Model List: ['vit_small_patch32_224', 'vit_small_patch16_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 384)\n",
      "Accuracy: 0.41020368194281237\n",
      "Model List: ['vit_base_patch32_384', 'vit_small_patch32_224', 'vit_small_patch16_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 768)\n",
      "Accuracy: 0.31368138324660066\n",
      "                                               Model  XGBoost       MLP  \\\n",
      "0       vit_base_patch32_384 + vit_small_patch32_224        0  0.772432   \n",
      "1       vit_base_patch32_384 + vit_small_patch16_224        0  0.767297   \n",
      "2      vit_small_patch32_224 + vit_small_patch16_224        0  0.751284   \n",
      "3  vit_base_patch32_384 + vit_small_patch32_224 +...        0  0.767297   \n",
      "\n",
      "   GaussianNB  Adaboost  KNN  RFClassifier  SVM_linear  SVM_sigmoid  SVM_RBF  \n",
      "0    0.347588         0    0             0           0            0        0  \n",
      "1    0.338805         0    0             0           0            0        0  \n",
      "2    0.410204         0    0             0           0            0        0  \n",
      "3    0.313681         0    0             0           0            0        0  \n",
      "Model List: ['vit_base_patch32_384', 'vit_small_patch32_224']\n",
      "no of example in each class before SMOTE: [2475 2441 1124 2511]\n",
      "no of example in each class after SMOTE: [2475 2441 2511 2511]\n",
      "no of features in X_train: (8551, 576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 67\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno of features in X_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Classify the data\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy)\n\u001b[0;32m     69\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m + \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(model_list)\n",
      "Cell \u001b[1;32mIn[3], line 41\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(X_train, y_train, X_test, y_test, classifier, search_type)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Predict the test data\u001b[39;00m\n\u001b[0;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:169\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    166\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:594\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:605\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 605\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = ['Model', \"XGBoost\", 'MLP', 'GaussianNB', \"Adaboost\", \"KNN\", \"RFClassifier\", \"SVM_linear\", \"SVM_sigmoid\", \"SVM_RBF\", ]\n",
    "\n",
    "dataframe = pd.DataFrame(columns=columns)\n",
    "# add 12 rows to the dataframe with zero values \n",
    "for model_list in top_model_combinations:\n",
    "    model_name = ' + '.join(model_list)\n",
    "    new_row = {'Model': model_name, \"XGBoost\":0, 'MLP': 0, 'GaussianNB': 0, \"Adaboost\": 0, \"KNN\": 0, \"RFClassifier\": 0, \"SVM_linear\": 0, \"SVM_sigmoid\": 0, \"SVM_RBF\": 0} \n",
    "    dataframe.loc[len(dataframe)] = new_row\n",
    "\n",
    "main_path = 'extracted_features_BT-large-4c'\n",
    "for ml_classifier in ML_CLASSIFIER:\n",
    "    for model_list in top_model_combinations:\n",
    "        print('Model List:', model_list)\n",
    "        ensemble_X_train = []\n",
    "        ensemble_X_test = []\n",
    "\n",
    "        for model in model_list:\n",
    "            sub_dir = os.path.join(main_path, model)\n",
    "            # Load the data\n",
    "            X_train = np.load(os.path.join(sub_dir, 'train_data_array_features.npy'))\n",
    "            y_train = np.load(os.path.join(sub_dir, 'train_data_array_labels.npy'))\n",
    "            X_test = np.load(os.path.join(sub_dir, 'test_data_array_features.npy'))\n",
    "            y_test = np.load(os.path.join(sub_dir, 'test_data_array_labels.npy'))\n",
    "\n",
    "\n",
    "            ## squeeze the dimensions 1 from the features \n",
    "            X_train = np.squeeze(X_train, axis=1)\n",
    "            X_test = np.squeeze(X_test, axis=1)\n",
    "\n",
    "            ## concatenate the features on axis 1\n",
    "            ensemble_X_train.append(X_train)\n",
    "            ensemble_X_test.append(X_test)\n",
    "            \n",
    "\n",
    "        X_train = np.concatenate(ensemble_X_train, axis=1)\n",
    "        y_train = y_train\n",
    "        X_test = np.concatenate(ensemble_X_test, axis=1)\n",
    "        y_test = y_test\n",
    "\n",
    "        ## apply the standard scaler and PCA\n",
    "        scaler = StandardScaler()\n",
    "        X_train_normalized = scaler.fit_transform(X_train)\n",
    "        X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "        # Step 2 & 3: Apply PCA\n",
    "        n_components = int(0.50 * X_train.shape[1])\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train = pca.fit_transform(X_train_normalized)\n",
    "        X_test = pca.transform(X_test_normalized)\n",
    "\n",
    "        ## no of example in each class\n",
    "        print(\"no of example in each class before SMOTE:\", np.bincount(y_train))\n",
    "\n",
    "\n",
    "        ## over sample the data\n",
    "        smote = SMOTE(sampling_strategy='minority')\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        ## no of example in each class\n",
    "        print(\"no of example in each class after SMOTE:\", np.bincount(y_resampled))\n",
    "\n",
    "\n",
    "        print(\"no of features in X_train:\", X_train.shape)\n",
    "\n",
    "        \n",
    "        # Classify the data\n",
    "        accuracy = classify(X_train, y_train, X_test, y_test, ml_classifier)\n",
    "        print('Accuracy:', accuracy)\n",
    "        model_name = ' + '.join(model_list)\n",
    "\n",
    "        dataframe.loc[dataframe['Model'] == model_name, ml_classifier] = accuracy\n",
    "\n",
    "    print(dataframe)\n",
    "    dataframe.to_csv('BT-large-4c-dataset_results_top_three_normalized_PCA_tuned_parameters.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224</td>\n",
       "      <td>0.760123</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.334981</td>\n",
       "      <td>0.730405</td>\n",
       "      <td>0.768637</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.785259</td>\n",
       "      <td>0.635719</td>\n",
       "      <td>0.754797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch16_224</td>\n",
       "      <td>0.764932</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.767703</td>\n",
       "      <td>0.783907</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.782297</td>\n",
       "      <td>0.617576</td>\n",
       "      <td>0.749797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit_small_patch32_224 + vit_small_patch16_224</td>\n",
       "      <td>0.791689</td>\n",
       "      <td>0.763919</td>\n",
       "      <td>0.410204</td>\n",
       "      <td>0.757814</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.781137</td>\n",
       "      <td>0.712453</td>\n",
       "      <td>0.569895</td>\n",
       "      <td>0.765811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224 +...</td>\n",
       "      <td>0.746745</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.321507</td>\n",
       "      <td>0.744797</td>\n",
       "      <td>0.799042</td>\n",
       "      <td>0.738784</td>\n",
       "      <td>0.769054</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.762297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model   XGBoost       MLP  \\\n",
       "0       vit_base_patch32_384 + vit_small_patch32_224  0.760123  0.764797   \n",
       "1       vit_base_patch32_384 + vit_small_patch16_224  0.764932  0.769797   \n",
       "2      vit_small_patch32_224 + vit_small_patch16_224  0.791689  0.763919   \n",
       "3  vit_base_patch32_384 + vit_small_patch32_224 +...  0.746745  0.764797   \n",
       "\n",
       "   GaussianNB  Adaboost       KNN  RFClassifier  SVM_linear  SVM_sigmoid  \\\n",
       "0    0.334981  0.730405  0.768637      0.738231    0.785259     0.635719   \n",
       "1    0.336305  0.767703  0.783907      0.760676    0.782297     0.617576   \n",
       "2    0.410204  0.757814  0.812421      0.781137    0.712453     0.569895   \n",
       "3    0.321507  0.744797  0.799042      0.738784    0.769054     0.636412   \n",
       "\n",
       "    SVM_RBF  \n",
       "0  0.754797  \n",
       "1  0.749797  \n",
       "2  0.765811  \n",
       "3  0.762297  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224</td>\n",
       "      <td>0.760123</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.334981</td>\n",
       "      <td>0.730405</td>\n",
       "      <td>0.768637</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.785259</td>\n",
       "      <td>0.635719</td>\n",
       "      <td>0.754797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch16_224</td>\n",
       "      <td>0.764932</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.767703</td>\n",
       "      <td>0.783907</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.782297</td>\n",
       "      <td>0.617576</td>\n",
       "      <td>0.749797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit_small_patch32_224 + vit_small_patch16_224</td>\n",
       "      <td>0.791689</td>\n",
       "      <td>0.763919</td>\n",
       "      <td>0.410204</td>\n",
       "      <td>0.757814</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.781137</td>\n",
       "      <td>0.712453</td>\n",
       "      <td>0.569895</td>\n",
       "      <td>0.765811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224 +...</td>\n",
       "      <td>0.746745</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.321507</td>\n",
       "      <td>0.744797</td>\n",
       "      <td>0.799042</td>\n",
       "      <td>0.738784</td>\n",
       "      <td>0.769054</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.762297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model   XGBoost       MLP  \\\n",
       "0       vit_base_patch32_384 + vit_small_patch32_224  0.760123  0.764797   \n",
       "1       vit_base_patch32_384 + vit_small_patch16_224  0.764932  0.769797   \n",
       "2      vit_small_patch32_224 + vit_small_patch16_224  0.791689  0.763919   \n",
       "3  vit_base_patch32_384 + vit_small_patch32_224 +...  0.746745  0.764797   \n",
       "\n",
       "   GaussianNB  Adaboost       KNN  RFClassifier  SVM_linear  SVM_sigmoid  \\\n",
       "0    0.334981  0.730405  0.768637      0.738231    0.785259     0.635719   \n",
       "1    0.336305  0.767703  0.783907      0.760676    0.782297     0.617576   \n",
       "2    0.410204  0.757814  0.812421      0.781137    0.712453     0.569895   \n",
       "3    0.321507  0.744797  0.799042      0.738784    0.769054     0.636412   \n",
       "\n",
       "    SVM_RBF  \n",
       "0  0.754797  \n",
       "1  0.749797  \n",
       "2  0.765811  \n",
       "3  0.762297  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>RFClassifier</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_sigmoid</th>\n",
       "      <th>SVM_RBF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224</td>\n",
       "      <td>0.760123</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.334981</td>\n",
       "      <td>0.730405</td>\n",
       "      <td>0.768637</td>\n",
       "      <td>0.738231</td>\n",
       "      <td>0.785259</td>\n",
       "      <td>0.635719</td>\n",
       "      <td>0.754797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch16_224</td>\n",
       "      <td>0.764932</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.336305</td>\n",
       "      <td>0.767703</td>\n",
       "      <td>0.783907</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.782297</td>\n",
       "      <td>0.617576</td>\n",
       "      <td>0.749797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit_small_patch32_224 + vit_small_patch16_224</td>\n",
       "      <td>0.791689</td>\n",
       "      <td>0.763919</td>\n",
       "      <td>0.410204</td>\n",
       "      <td>0.757814</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.781137</td>\n",
       "      <td>0.712453</td>\n",
       "      <td>0.569895</td>\n",
       "      <td>0.765811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vit_base_patch32_384 + vit_small_patch32_224 +...</td>\n",
       "      <td>0.746745</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.321507</td>\n",
       "      <td>0.744797</td>\n",
       "      <td>0.799042</td>\n",
       "      <td>0.738784</td>\n",
       "      <td>0.769054</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.762297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model   XGBoost       MLP  \\\n",
       "0       vit_base_patch32_384 + vit_small_patch32_224  0.760123  0.764797   \n",
       "1       vit_base_patch32_384 + vit_small_patch16_224  0.764932  0.769797   \n",
       "2      vit_small_patch32_224 + vit_small_patch16_224  0.791689  0.763919   \n",
       "3  vit_base_patch32_384 + vit_small_patch32_224 +...  0.746745  0.764797   \n",
       "\n",
       "   GaussianNB  Adaboost       KNN  RFClassifier  SVM_linear  SVM_sigmoid  \\\n",
       "0    0.334981  0.730405  0.768637      0.738231    0.785259     0.635719   \n",
       "1    0.336305  0.767703  0.783907      0.760676    0.782297     0.617576   \n",
       "2    0.410204  0.757814  0.812421      0.781137    0.712453     0.569895   \n",
       "3    0.321507  0.744797  0.799042      0.738784    0.769054     0.636412   \n",
       "\n",
       "    SVM_RBF  \n",
       "0  0.754797  \n",
       "1  0.749797  \n",
       "2  0.765811  \n",
       "3  0.762297  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
